{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alike-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "friendly-herald",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataset_specification import DatasetSpecification\n",
    "from data_preprocessing_toolkit import DataPreprocessingToolkit\n",
    "from people_identifier import PeopleIdentifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-signal",
   "metadata": {},
   "source": [
    "# Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "solid-crisis",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\hotel_data\\\\hotel_data_original.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-da017be5c6bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hotel_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moriginal_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hotel_data_original.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moriginal_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"\\\\N\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wojciech\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wojciech\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wojciech\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wojciech\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wojciech\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wojciech\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wojciech\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\hotel_data\\\\hotel_data_original.csv'"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "original_data = pd.read_csv(os.path.join(data_path, \"hotel_data_original.csv\"), index_col=0)\n",
    "\n",
    "original_data = original_data.replace({\"\\\\N\": \"\"})\n",
    "original_data = original_data.fillna(\"\")\n",
    "\n",
    "numeric_columns = [\"n_people\", \"n_children_1\", \"n_children_2\", \"n_children_3\",\n",
    "                   \"discount\", \"accommodation_price\", \"meal_price\", \"service_price\",\n",
    "                   \"paid\"]\n",
    "\n",
    "for column in numeric_columns:\n",
    "    original_data.loc[:, column] = pd.to_numeric(original_data.loc[:, column], errors=\"coerce\")\n",
    "\n",
    "original_data = original_data.astype(\n",
    "        {\n",
    "            \"date_from\": np.datetime64,\n",
    "            \"date_to\": np.datetime64,\n",
    "            \"booking_time\": np.datetime64,\n",
    "            \"booking_date\": np.datetime64,\n",
    "            \"n_people\": np.int64,\n",
    "            \"n_children_1\": np.int64,\n",
    "            \"n_children_2\": np.int64,\n",
    "            \"n_children_3\": np.int64,\n",
    "            \"discount\": np.float64,\n",
    "            \"accommodation_price\": np.float64,\n",
    "            \"meal_price\": np.float64,\n",
    "            \"service_price\": np.float64,\n",
    "            \"paid\": np.float64,\n",
    "        }\n",
    "    )\n",
    "\n",
    "display(original_data.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-lingerie",
   "metadata": {},
   "source": [
    "# Preprocess the data\n",
    "\n",
    "- Identify users by client_id, name hash, phone hash, email hash.\n",
    "- Fix date_to - originally it points to the last full day of stay, not the departure date.\n",
    "- Add length of stay.\n",
    "- Add book to arrival.\n",
    "- Add number of rooms (important for group reservations).\n",
    "- Add indicator for stays encompasing a weekend.\n",
    "- Add night price.\n",
    "- Fix book to arrival to be not smaller than 0.\n",
    "- Filter out companies as recommendations for such clients should work differently.\n",
    "- Aggregate group reservations into single interactions.\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "In the file data_preprocessing/data_preprocessing_toolkit write code for the following methods which work on the DataFrame with hotel data:\n",
    "  - add_length_of_stay - Adds length_of_stay column which is the difference between date_from and date_to (in days), i.e. the number of nights the customer stayed at the hotel.\n",
    "  - add_book_to_arrival - Adds book_to_arrival column which is the difference between date_from and booking_date (in days).\n",
    "  - add_weekend_stay - Adds weekend_stay column with 'True'/'False' strings indicating if the interval date_from to date_to contains any weekend days (defined as Friday and Saturday).\n",
    "  - add_night_price - Adds night_price column with the average price per one night per room - calculated as accomodation_price divided by length_of_stay and by n_rooms (there can be many rooms in group reservations - 'n_rooms' column).\n",
    "  - sum_npeople - Sums n_people, n_children_1, n_children_2, n_children_3 and sets the result to the n_people column.\n",
    "  - filter_out_company_clients - Filters out company clients is_company=0.\n",
    "  - filter_out_long_stays - Leaves only stays with length_of_stay less or equal to 21.\n",
    "  - filter_out_low_prices - Leaves only stays with accommodation price bigger than 50. Smaller prices are considered not reliable and likely a mistake of the hotel staff.\n",
    "  - aggregate_group_reservations - Aggregates every group reservation into one reservation with aggregated data (for self.sum_columns a sum is taken, for self.mean_columns a mean, for self.mode_columns a mode, for self.first_columns the first value). This one is the most challenging - see instructions in the py file (remember that with the %load_ext autoreload %autoreload 2 options in the first cell of this notebook you don't have to restart the notebook - the changes in the py file will be immediately used in the notebook whenever a method from the py file is invoked).\n",
    "  \n",
    "You have to pass all assertions in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-iceland",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessed_data = original_data.copy()\n",
    "\n",
    "dataset_specification = DatasetSpecification()\n",
    "dp_toolkit = DataPreprocessingToolkit()\n",
    "\n",
    "id_column_names = dataset_specification.get_id_columns()\n",
    "\n",
    "people_identifier = PeopleIdentifier()\n",
    "preprocessed_data = people_identifier.add_pid(preprocessed_data, id_column_names, \"user_id\")\n",
    "\n",
    "preprocessed_data = dp_toolkit.filter_out_company_clients(preprocessed_data)  # Code this method\n",
    "preprocessed_data = dp_toolkit.filter_out_low_prices(preprocessed_data)  # Code this method\n",
    "\n",
    "preprocessed_data = dp_toolkit.fix_date_to(preprocessed_data)\n",
    "preprocessed_data = dp_toolkit.add_length_of_stay(preprocessed_data)  # Code this method\n",
    "\n",
    "preprocessed_data = dp_toolkit.filter_out_long_stays(preprocessed_data)  # Code this method\n",
    "\n",
    "preprocessed_data = dp_toolkit.add_book_to_arrival(preprocessed_data)  # Code this method\n",
    "preprocessed_data = dp_toolkit.add_weekend_stay(preprocessed_data)  # Code this method\n",
    "preprocessed_data = dp_toolkit.add_nrooms(preprocessed_data)\n",
    "preprocessed_data = dp_toolkit.sum_npeople(preprocessed_data)  # Code this method\n",
    "preprocessed_data = dp_toolkit.clip_book_to_arrival(preprocessed_data)\n",
    "\n",
    "preprocessed_data = dp_toolkit.aggregate_group_reservations(preprocessed_data)  # Code this method\n",
    "\n",
    "preprocessed_data = dp_toolkit.add_night_price(preprocessed_data)  # Code this method\n",
    "\n",
    "preprocessed_data = preprocessed_data.reset_index(drop=True)\n",
    "\n",
    "assert len(preprocessed_data.loc[preprocessed_data[\"is_company\"] == 1]) == 0\n",
    "assert len(preprocessed_data.loc[preprocessed_data[\"length_of_stay\"] > 21]) == 0\n",
    "assert len(preprocessed_data.loc[preprocessed_data[\"accommodation_price\"] <= 50]) == 0\n",
    "\n",
    "assert preprocessed_data.iloc[1]['length_of_stay'] == 3\n",
    "assert preprocessed_data.iloc[2]['length_of_stay'] == 2\n",
    "assert preprocessed_data.iloc[3]['length_of_stay'] == 7\n",
    "\n",
    "assert preprocessed_data.iloc[2150]['book_to_arrival'] == 11\n",
    "assert preprocessed_data.iloc[2151]['book_to_arrival'] == 28\n",
    "assert preprocessed_data.iloc[2152]['book_to_arrival'] == 12\n",
    "\n",
    "assert preprocessed_data.iloc[2150]['weekend_stay'] == 'False'\n",
    "assert preprocessed_data.iloc[2151]['weekend_stay'] == 'True'\n",
    "assert preprocessed_data.iloc[2152]['weekend_stay'] == 'False'\n",
    "\n",
    "assert preprocessed_data.iloc[3650]['n_people'] == 2\n",
    "assert preprocessed_data.iloc[3651]['n_people'] == 4\n",
    "assert preprocessed_data.iloc[3652]['n_people'] == 1\n",
    "\n",
    "assert preprocessed_data.iloc[0]['night_price'] == 330.76\n",
    "assert preprocessed_data.iloc[1]['night_price'] == 231.13\n",
    "assert preprocessed_data.iloc[2]['night_price'] == 183.40\n",
    "\n",
    "# Assertions for group reservations\n",
    "\n",
    "assert preprocessed_data.iloc[15258]['rate_plan'] == 'Nonref'\n",
    "assert preprocessed_data.iloc[15259]['rate_plan'] == 'Standard'\n",
    "assert preprocessed_data.iloc[15260]['rate_plan'] == 'Standard'\n",
    "assert preprocessed_data.iloc[15258]['accommodation_price'] == 1397.06\n",
    "assert preprocessed_data.iloc[15261]['accommodation_price'] == 2953.10\n",
    "assert preprocessed_data.iloc[15264]['accommodation_price'] == 1738.80\n",
    "assert preprocessed_data.iloc[15258]['n_people'] == 6\n",
    "assert preprocessed_data.iloc[15259]['n_people'] == 7\n",
    "assert preprocessed_data.iloc[15260]['n_people'] == 11\n",
    "assert preprocessed_data.iloc[15265]['night_price'] == 206.67\n",
    "assert preprocessed_data.iloc[15266]['night_price'] == 138.92\n",
    "assert preprocessed_data.iloc[15267]['night_price'] == 119.07\n",
    "assert preprocessed_data.iloc[15261]['room_group_id'] == 483\n",
    "assert preprocessed_data.iloc[15266]['room_group_id'] == 78\n",
    "assert preprocessed_data.iloc[15267]['room_group_id'] == 463\n",
    "\n",
    "display(preprocessed_data.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-river",
   "metadata": {},
   "source": [
    "# Bucket important features to reduce the offer space size\n",
    "\n",
    "Without this step every pair (user_id, item_id) would have at most a single interaction. The base item space has around $2^{25} \\sim 3.3 \\text{mln}$ elements. Therefore, values for selected features are aggregated into buckets:\n",
    "\n",
    "```python\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "  - term - the term of the arrival date,\n",
    "  - length_of_stay_bucket - aggregated length of stay,\n",
    "  - rate_plan - rate plan which distinguishes if a given booking was refundable or nonrefundable (in reality rate plans are much more complex, they define prices for all rooms for every date, they include features like free breakfast, wine in the room etc.),\n",
    "  - room_segment - for every room its average price is calculated, then every room assigned to an appropriate price range, which is a proxy for room quality,\n",
    "  - n_people_bucket - aggregated number of people in a reservation,\n",
    "  - weekend_stay - indicates if the stay encompassed a weekend.\n",
    "\n",
    "The buckets are chosen based on expert knowledge of people working in the hotel industry for many years. Alternatively, clustering techniques could be used, but on a relatively small dataset expert methods are typically better.\n",
    "\n",
    "The above aggregations reduce the number of possible items to $8 * 4 * 2 * 5 * 4 * 2 = 2560$.\n",
    "\n",
    "### The recommenders will be trained and evaluated on such aggregated data. To get a proper offer for a user one would have to decode those buckets into specific values, but this is a much easier task and can be achieved based on simple rules.\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "In the file data_preprocessing/data_preprocessing_toolkit write code for the map_night_price_to_room_segment_buckets method. You must calculate the average of night prices for every **room_group_id** and map those prices to buckets (you can apply the map_value_to_bucket method which is available in the data_preprocessing_toolkit, the buckets are available under self.room_segment_buckets). The new column should be named 'room_segment'. You have to pass all assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-rendering",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessed_data = dp_toolkit.map_dates_to_terms(preprocessed_data)\n",
    "preprocessed_data = dp_toolkit.map_lengths_of_stay_to_nights_buckets(preprocessed_data)\n",
    "preprocessed_data = dp_toolkit.map_night_prices_to_room_segment_buckets(preprocessed_data)  # Code this method\n",
    "preprocessed_data = dp_toolkit.map_npeople_to_npeople_buckets(preprocessed_data)\n",
    "\n",
    "assert preprocessed_data.iloc[4]['room_segment'] == '[0-160]'\n",
    "assert preprocessed_data.iloc[1]['room_segment'] == '[160-260]'\n",
    "assert preprocessed_data.iloc[0]['room_segment'] == '[260-360]'\n",
    "assert preprocessed_data.iloc[2820]['room_segment'] == '[360-500]'\n",
    "\n",
    "preprocessed_data = dp_toolkit.map_item_to_item_id(preprocessed_data)\n",
    "\n",
    "preprocessed_data.to_csv(os.path.join(data_path, \"hotel_data_preprocessed.csv\"))\n",
    "\n",
    "display(preprocessed_data.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-biography",
   "metadata": {},
   "source": [
    "# Base statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of users: {}\".format(len(preprocessed_data['user_id'].unique())))\n",
    "print()\n",
    "print(\"Number of items: {}\".format(len(preprocessed_data['item_id'].unique())))\n",
    "print()\n",
    "print(\"Number of interactions: {}\".format(len(preprocessed_data)))\n",
    "print()\n",
    "\n",
    "n_user = preprocessed_data.loc[:, ['user_id', 'item_id']].groupby('item_id').count().sort_values(by='user_id', ascending=False)\n",
    "n_user = n_user.rename(columns={'user_id': 'n_users'})\n",
    "display(n_user.head(10))\n",
    "\n",
    "n_item = preprocessed_data.loc[:, ['user_id', 'item_id']].groupby('user_id').count().sort_values(by='item_id', ascending=False)\n",
    "n_item = n_item.rename(columns={'item_id': 'n_items'})\n",
    "display(n_item.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-knitting",
   "metadata": {},
   "source": [
    "# Prepare the dataset for recommenders\n",
    "\n",
    "One could consider many features describing each interaction but from the business perspective term, length_of_stay_bucket, rate_plan, room_segment, n_people_bucket, weekend_stay are the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "interactions_df = preprocessed_data.loc[:, ['user_id', 'item_id'] + item_features]\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df['term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df['length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df['rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df['room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df['n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df['weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "interactions_df.to_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"))\n",
    "\n",
    "display(interactions_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-colombia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
